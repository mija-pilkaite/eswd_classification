{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sentence_transformers\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import trange\n",
    "import random\n",
    "import spacy\n",
    "from spacy_language_detection import LanguageDetector\n",
    "import math\n",
    "import spacy_fastlang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def convert_text_to_csv(input_file, output_file):\n",
    "    # Open the input text file for reading\n",
    "    with open(input_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Open the output CSV file for writing\n",
    "    with open(output_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write each line as a separate row in the CSV file\n",
    "        for line in lines:\n",
    "            writer.writerow([line.strip()])  \n",
    "    print(\"Conversion completed successfully.\")\n",
    "\n",
    "\n",
    "# Usage example\n",
    "input_file = 'non_severe_cleaned.txt'\n",
    "output_file = 'false_data.csv'\n",
    "convert_text_to_csv(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_false = pd.read_csv('false_data.csv', header=None)\n",
    "df_false['false'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_false.columns = ['REFERENCE', 'false']\n",
    "df_false.to_csv('false_data.csv', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['REFERENCE', 'TYPE_EVENT']\n",
    "df_true = pd.read_csv('eswd.csv', usecols=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true = df_true.dropna(subset=['REFERENCE'])  # we are at 12871 rows now\n",
    "df_true.drop_duplicates(inplace=True) \n",
    "df_true = df_true[~df_true['REFERENCE'].str.contains(\"Report via Kachelmannwetter.com\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a column indicating whether it is a false data or no, so here add all 1s\n",
    "df_true['false'] = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "nlp1 = spacy.load(\"en_core_web_sm\")\n",
    "nlp2 = spacy.load(\"fr_core_news_sm\")\n",
    "nlp1.add_pipe(\"language_detector\", last=True)\n",
    "df_true['language'] = df_true['REFERENCE'].apply(lambda x: nlp1(x)._.language)\n",
    "df_en = df_true[df_true['language'] == 'en']\n",
    "df_fr = df_true[df_true['language'] == 'fr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_fr = df_fr[['REFERENCE', 'false', 'TYPE_EVENT']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-19ac9588dd89>:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_fr = df_fr[df_true.TYPE_EVENT != 'AVALANCHE']\n"
     ]
    }
   ],
   "source": [
    "df_fr = df_fr[df_true.TYPE_EVENT != 'AVALANCHE']\n",
    "df_fr = df_fr[['REFERENCE', 'false']]\n",
    "#take 500 random samples from the french data\n",
    "df_fr = df_fr.sample(n=500, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           REFERENCE  false\n",
      "0  \"Bilan des violents orages en France les mardi...      1\n",
      "1  \"Les orages ont causé des inondations dans plu...      1\n",
      "2  \"D’importants dégâts au Coteau causés par la g...      1\n",
      "3  \"Saint-Loup-sur-Semouse : une mini-tornade sur...      1\n",
      "4  \"Raisins explosés par la grêle et vignerons à ...      1\n",
      "(938, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df_fr, df_false], ignore_index=True)\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "#to csv\n",
    "df.to_csv('data.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['REFERENCE'] = df['REFERENCE'].apply(lambda x: x.split())\n",
    "df['REFERENCE'] = df['REFERENCE'].apply(\n",
    "    lambda x: [token.text for token in nlp2(\" \".join(x)) if not token.is_punct])\n",
    "df['REFERENCE'] = df['REFERENCE'].apply(\n",
    "    lambda x: [token.text for token in nlp2(\" \".join(x)) if not token.is_stop])\n",
    "df['REFERENCE'] = df['REFERENCE'].apply(\n",
    "    lambda x: [token.lemma_ for token in nlp2(\" \".join(x))])\n",
    "#now join tokenized words into one string\n",
    "df['REFERENCE'] = df['REFERENCE'].apply(lambda x: \" \".join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #use bag of words\n",
    "# cnt_vec = CountVectorizer(ngram_range=(1,2), max_features=30000)\n",
    "# bow_train = cnt_vec.fit_transform(df['REFERENCE'])\n",
    "# bow_train = bow_train.toarray()\n",
    "# #add the transformed data to the dataframe\n",
    "# df_bow = pd.DataFrame(bow_train, columns=cnt_vec.get_feature_names())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.9946694120338595\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the DataFrame\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "cnt_vec = CountVectorizer()\n",
    "bow_train = cnt_vec.fit_transform(df['REFERENCE'])\n",
    "bow_train = bow_train.toarray()\n",
    "\n",
    "df_bow = pd.DataFrame(bow_train, columns=cnt_vec.get_feature_names())\n",
    "\n",
    "df_bow['false'] = df['false']\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "\n",
    "model = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for train_idx, val_idx in kf.split(df_bow):\n",
    "\n",
    "    train_data = df_bow.iloc[train_idx]\n",
    "    val_data = df_bow.iloc[val_idx]\n",
    "\n",
    "\n",
    "    X_train, y_train = train_data.iloc[:, :-1].values, train_data.iloc[:, -1].values\n",
    "    X_val, y_val = val_data.iloc[:, :-1].values, val_data.iloc[:, -1].values\n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "print(\"Average accuracy:\", avg_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will analyze the data using spacy and use a tf-idf vector to build a binary classificator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the misclassified samples, their predicted and true labels and reference\n",
    "for i in range(len(y_val)):\n",
    "    if y_val[i] != y_pred[i]:\n",
    "        print(\"Predicted:\", y_pred[i], \"True:\", y_val[i], \"Reference:\", df.iloc[val_idx[i]]['REFERENCE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(df['REFERENCE'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df['vectorized_reference'] = denselist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the data\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df = df[['vectorized_reference', 'false', 'REFERENCE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vectorized_reference', 'false', 'REFERENCE'], dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.9904140928849234\n",
      "\n",
      "Incorrectly classified references:\n",
      "1: Haute-Savoie glissement terrain bloquer route Thyez dauphiner Libéré 15 July 2021 for suscriber only (True label: 1, Predicted label: 0)\n",
      "2: grêle sud-est orage l ' Ouest (True label: 0, Predicted label: 1)\n",
      "3: météo France surprendre (True label: 0, Predicted label: 1)\n",
      "4: Mickael B. observatoir ciel Orageux Tornade Médoc 2018 2019 (True label: 1, Predicted label: 0)\n",
      "5: match xv never reporter cause vent Péméja never furieux réaction vidéo charente libre 01 March 2020 (True label: 1, Predicted label: 0)\n",
      "6: témoignage voisin n ’ fumée c ’ toit partir voir pire REDON MAVILLE 24 nov 2022 (True label: 1, Predicted label: 0)\n",
      "7: météo 2022 lodévoi ancrée (True label: 0, Predicted label: 1)\n",
      "8: tempête vent passer Corse bien résister Corse matin 10 Dec 2018 (True label: 1, Predicted label: 0)\n",
      "9: 2022 bien être l ' année chaude France (True label: 0, Predicted label: 1)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "\n",
    "model = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "mistakes = []  # List to store incorrectly classified references\n",
    "\n",
    "for train_idx, val_idx in kf.split(df):\n",
    "    train_data = df.iloc[train_idx]\n",
    "    val_data = df.iloc[val_idx]\n",
    "\n",
    "    X_train_tfidf = pd.DataFrame(train_data['vectorized_reference'].tolist())\n",
    "    X_val_tfidf = pd.DataFrame(val_data['vectorized_reference'].tolist())\n",
    "\n",
    "    y_train, y_val = train_data['false'], val_data['false']\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_val_tfidf)\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Find and store incorrectly classified references\n",
    "    for idx, (true_label, pred_label) in enumerate(zip(y_val, y_pred)):\n",
    "        if true_label != pred_label:\n",
    "            mistakes.append((val_data.iloc[idx]['REFERENCE'], true_label, pred_label))\n",
    "\n",
    "# Average\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "print(\"Average accuracy:\", avg_accuracy)\n",
    "\n",
    "# Print incorrectly classified references\n",
    "print(\"\\nIncorrectly classified references:\")\n",
    "for idx, (ref, true_label, pred_label) in enumerate(mistakes, start=1):\n",
    "    print(f\"{idx}: {ref} (True label: {true_label}, Predicted label: {pred_label})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #use logistic regression and bag of words to classify events as false or true\n",
    "# logreg = sklearn.linear_model.LogisticRegression()\n",
    "# logreg.fit(x_bow_train, y_bow_train)\n",
    "# y_pred = logreg.predict(x_bow_test)\n",
    "# accuracy = sklearn.metrics.accuracy_score(y_bow_test, y_pred)\n",
    "# print(accuracy)\n",
    "# print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(x_bow_test, y_bow_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mijap\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-6bfb58de060d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"True:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Reference:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'REFERENCE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mijap\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mijap\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mijap\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_val)):\n",
    "    if y_val[i] != y_pred[i]:\n",
    "        print(\"Predicted:\", y_pred[i], \"True:\", y_val[i], \"Reference:\", df.iloc[val_idx[i]]['REFERENCE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eyewitness report météo d ' antoine météo Limousin Facebook 04 JUN 2022 n ' jamais 30 an jean-luc pierron maire Crocq toucher intempérie Creuse France Bleu 05 JUN 2022\n",
      "Orages savoie Haute-Savoie foudre frappe transformateur route couper France Bleu 24 OCT 2022\n",
      "météo 2022 lodévoi ancrée\n",
      "week end ensoleiller nouveau\n",
      "Liévin petit tornade touch cité castor famille reloger voix Nord 16 feb 2020\n",
      "ws report météo France METEOFRANCE.com 20 mar 2018\n",
      "hautes-pyrénée grêle miner champ agriculteur garder espoir ladepeche.fr 22 JUN 2021 RAD\n",
      "sant Galdric faire -t il venir plui\n",
      "Orages Cher pluie diluvien grêle vent dégât France Bleu cher 22 june 2022\n",
      "devoir faire ' 35 degré c l ' Hérault\n",
      "vent exploiter villag\n",
      "ogeu culture être toucher plein fouet l ’ averse grêle republique pyréner 21 JUN 2022 Eyewitness report République pyréner Facebook 21 JUN 2022\n",
      "l ' absence plui bassin thau régime sec\n",
      "Allemagne Autriche Belgique octobre 2022\n",
      "météo Herbiers Facebook 21 oct 2021\n",
      "actualité observation météo nouveau Aquitaine v. Facebook 19 JUN 2022\n",
      "neige verglas 6 000 kilomètre route aveyronnais\n",
      "intempérie Occitanie 600 foyer priver d ' électricité 3 département samedi soir ladepeche.fr 27 june 2020\n",
      "États-Unis bilan tempête siècl continuer\n",
      "Orages grêle lande inquiétude culture Sud Ouest 10 may 2020\n",
      "ws report météo France METEOFRANCE.com 03 feb 2018\n",
      "actualité vigilance météo facebook 27 aug 2022\n",
      "l ’ orage provoquer gros dégât pleudaniel inondation incendier ouest-france 06 june 2022\n",
      "eyewitnesse report observation météo l ' Allier group Facebook 05 JUN 2022 Eyewitness report météo Auvergne rhône Alpes Facebook 04 JUN 2022\n",
      "St Rome Tarn bonhomme neige écolo\n",
      "crue inondation vent violent avalanch 16\n",
      "éolien mer emploi local biodiversité RWE devenir\n",
      "Guillaume Woznica Facebook 10 féb 2020\n",
      "pic chaleur venir 18 département\n",
      "mois d ' octobre chaud jamais\n",
      "lande maison toucher foudre SUD ouest 13 JUN 2022\n",
      "violer orage grêle traverser mézenc meygal l ' Yssingelais COMMERE 43 03 jul 2022\n",
      "aude grêle laisse arbre haché menu petit village Montagne Noire centpourcent.com 16 aug 2022 Eyewitness report météo 13 facebook 17 aug 2022\n",
      "Orages Occitanie l ' ouest l ' aude toucher route inonder France Bleu 09 2021\n",
      "donzère jour l ’ orage grêle arboriculteur craignent déclassement fruit dauphiner 16 JUN 2020\n",
      "Vallauris Monaco image impressionnant grêle orage Alpes Maritimes francetvinfo.fr 20 Dec 2018\n",
      "savoie 100 tonne neige héliporter\n",
      "l ' Hérault placer vigilance jaune neige\n",
      "vent d ' autan marin tramontane mistral savoir -vous bien\n",
      "l ' hiver pluie abondant mercredi\n",
      "température hivernal week end\n",
      "ws report météo France METEOFRANCE.com 18 JUL 2018\n",
      "gris humide frais France connaître\n",
      "redoux persister Sud pluie température\n",
      "Eyewitness report météo ardèche Facebook 06 JUN 2022\n",
      "dégat vent midilibre.fr\n",
      "vidéo Tempête Alex rafal 186 kilomètre heure Bretagne alerte rouge côte d ’ Azur Sud Ouest 02 oct 2020\n",
      "Coup vent Fougères trentaine d ’ arbre casser déraciner parc d ’ maison actu.fr 29 feb 2020\n",
      "circulation l ' a75 difficile plui\n",
      "l ' être presque 29 degré c Sud\n",
      "vent d ' autan blanc noir sibérie\n",
      "ws report météo France METEOFRANCE.com 17 JUN 2018\n",
      "météo Express v. twitter 14 sep 2021 sat\n",
      "tempête Filomena image incroyable chute\n",
      "climat satellite précis intelligence artificiel\n",
      "Manche 230 éclair nuit dernier maison frappé foudre presse manche 14 sep 2021 RAD\n",
      "l ' esprit vent jeu pist numérique gratuit\n",
      "soleil température localement estival\n",
      "Eyewitness report météo89 Facebook 05 JUN 2022\n",
      "record nuit doux Paris\n",
      "Orages impressionnant couler boue Ferrette haut rhin FRANCE bleu 09 JUN 2021 RAD\n",
      "vingt-troi participant concour peintre perturbé\n",
      "ws report météo France METEOFRANCE.com 02 OCT 2018\n",
      "météo pâques plui douceur Sud\n",
      "météo franc-comtois v. Facebook 26 JUN 2022 Eyewitness report météo doub direct Facebook 26 JUN 2022\n",
      "vague historique chaleur froid intense Noël\n",
      "ws report météo France METEOFRANCE.com 30 JUN 2019\n",
      "bientôt vrai chaleur d ' être pays\n",
      "e-météo service Facebook 9 may 2020\n",
      "ws report météo France METEOFRANCE.com 11 jan 2019\n",
      "Orages Drôme ardèche 650 foyer priver d ' électricité circulation train repri dauphiner 8 2022 lightning Detection\n",
      "température baisse beaucoup plui\n",
      "Eyewitness report Lyon météo Facebook 07 sep 2022\n",
      "Barneville Carteret foudre s ' abat maison départ fumer comble manche libre 13 feb 2020\n",
      "France vigilanc orage ciel gris généraliser\n",
      "vendée coupure courant inondation intervention pompier bilan orage ouest-france 10 may 2020\n",
      "tuile envoler arbre déraciner l ’ orage dégât bien Public 20 Jun 2019\n",
      "fort épisode orageux partir soir\n",
      "saint glace commencer jeudi\n",
      "orage pluie 62 département placer vigilance\n",
      "magala plui n ' réussir gâcher fête Pinède\n",
      "falloir remonter 1993 1995 retrouver\n",
      "arrivée d ' air polaire vigilanc météo neige t-\n",
      "nouveau chute neige Lozère\n",
      "ws report météo France METEOFRANCE.com 07 OCT 2018\n"
     ]
    }
   ],
   "source": [
    "#print out the reference column for the vectors that were misclassified\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] != test['false'].tolist()[i]:\n",
    "        print(test['REFERENCE'].tolist()[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
